---
title: "SSAC_2023"
author: "Lorenzo Dube and Xander Schwartz"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(zipcodeR)
```

#### Data Cleaning

Output of the below cell is two dataframes: 'continuous_df' which is all of the continuous data from the dataset and 'categorical_df' which is all of the categorical data.  Those with two categories have been 'one hot' encoded.

```{r Data_Clean}

cat_data_read <- function(behavior, customer) {
customer = read_csv(customer)
behavior = read_csv(behavior)

customer <- customer[, colSums(!is.na(customer)) > 0] #remove all NA only columns
customer <- customer[, !grepl("input_indv", names(customer))] #remove input_indv columns
behavior <- behavior[, colSums(!is.na(behavior)) > 0] #remove all NA only columns

df <- merge(customer, behavior, by = "acct_id")

one_hot_column_list <- sapply(df, function(x) all(is.na(x) | x %in% c(0,1)))
cont_value_column_list = !one_hot_column_list
one_hot_column_list[1] = TRUE

one_hot_df <- df[, one_hot_column_list]
one_hot_df[is.na(one_hot_df)] <- 0

cont_val_df = df[, cont_value_column_list]
cont_val_list2 <- sapply(cont_val_df, function(col) all(is.numeric(col) | is.na(col)))
cont_val_list2[1] = TRUE
continuous_df <- cont_val_df[, cont_val_list2]

other_cat_list = !cont_val_list2
other_cat_list[1] = TRUE
other_cat_df <- cont_val_df[, other_cat_list]

categorical_df = merge(one_hot_df, other_cat_df, by = 'acct_id')}


cont_data_read <- function(behavior, customer) {
customer = read_csv(customer)
behavior = read_csv(behavior)

customer <- customer[, colSums(!is.na(customer)) > 0] #remove all NA only columns
customer <- customer[, !grepl("input_indv", names(customer))] #remove input_indv columns
behavior <- behavior[, colSums(!is.na(behavior)) > 0] #remove all NA only columns

df <- merge(customer, behavior, by = "acct_id")

one_hot_column_list <- sapply(df, function(x) all(is.na(x) | x %in% c(0,1)))
cont_value_column_list = !one_hot_column_list
one_hot_column_list[1] = TRUE

one_hot_df <- df[, one_hot_column_list]
one_hot_df[is.na(one_hot_df)] <- 0

cont_val_df = df[, cont_value_column_list]
cont_val_list2 <- sapply(cont_val_df, function(col) all(is.numeric(col) | is.na(col)))
cont_val_list2[1] = TRUE
continuous_df <- cont_val_df[, cont_val_list2]}

kc_categorical= cat_data_read('KC_Behavior.csv', 'KC_Cust.csv')
kc_continuous = cont_data_read('KC_Behavior.csv', 'KC_Cust.csv')
lv_categorical = cat_data_read('Lville_Behavior.csv', 'LVille_Cust.csv')
lv_continuous = cont_data_read('Lville_Behavior.csv', 'LVille_Cust.csv')
vb_categorical = cat_data_read('VB_Behavior2.csv', 'VB_Cust.csv')
vb_continuous = cont_data_read('VB_Behavior2.csv', 'VB_Cust.csv')


```
```{r}
categorical <- lv_categorical %>% mutate(CityName = "Lousiville") %>%
  bind_rows(vb_categorical %>%  mutate(CityName = "Virginia Beach")) %>%
  bind_rows(kc_categorical %>% mutate(CityName = "Kansas City")) 

continuous <- lv_continuous %>% mutate(CityName = "Lousiville") %>%
  bind_rows(vb_continuous %>%  mutate(CityName = "Virginia Beach")) %>%
  bind_rows(kc_continuous %>% mutate(CityName = "Kansas City")) %>%
  mutate(personicx_group  = factor(case_when(psx_group_id <= 2 ~ "Youth",
                                      psx_group_id <= 8 ~ "CareerBuilding",
                                      psx_group_id <= 14 ~ "Earning",
                                      psx_group_id <= 20~ "LateCareer",
                                      psx_group_id > 20 ~ "Retired",
                                      T ~ "NA"
                                      ),ordered = T))

allData <- left_join(continuous, categorical) %>% 
  filter(brkr_ind == 0|is.na(brkr_ind))
  
```

Removing all accounts for which there are multiple lines for whatever reason. ~1000 observations removed. 

```{r Remove Duplicate Accts}
counts_cat <- 
  categorical %>% 
  group_by(acct_id) %>% 
  summarise(ct = n()) %>% 
  arrange(ct)

table(counts_cat$ct)

counts_cont <- 
  categorical %>%
  group_by(acct_id) %>% 
  summarise(ct = n()) %>% 
  arrange(ct)

table(counts_cont$ct)

categorical_minus_duplicates <- 
  categorical %>%
  left_join(counts_cat) %>% 
  filter(ct == 1) %>%
  select(-ct)

continuous_minus_duplicates <- 
  continuous %>%
  left_join(counts_cont) %>% 
  filter(ct == 1) %>%
  select(-ct)
```

```{r}
data_train <- allData %>% filter(!is.na(e3_spend_pe_m_sports) & !is.na(financial_pct_score) & !is.na(psx_group_id) &  !is.na(client_pe_tkt_cnt))

    model <- randomForest::randomForest(e3_spend_pe_m_sports ~ financial_pct_score + personicx_group + client_pe_tkt_cnt, data = data_train, ntree = 1000)
    
save(file = "model.rda", model)    
  
data_train$predicted_dollars <- predict(object = model, data = data_train)

data_train <- data_train%>%mutate(PredictedTotalSpend = predicted_dollars * e3_events_cnt)

spend_by_city <- data_train %>% 
  group_by(CityName) %>% 
  summarise(City_Spend = mean(predicted_dollars),
            City_Spend_sd = sd(predicted_dollars),
            total_spend = sum(predicted_dollars),
            sample_size = n())

ggplot(data_train, aes(x= PredictedTotalSpend, fill = CityName)) + geom_density(alpha= .5) + xlim(0,2000) + labs(fill = "City", x = "Predicted Total Spend")

ggplot(data_train, aes(x = predicted_dollars, col = log10(PredictedTotalSpend), y = e3_events_cnt)) + geom_point() + labs(x = "Per Event $", y = "# Events", col = "Log 10 3Y Predicted Total $") + ylim(0,60)
```

```{r}
data_train_concert <- allData %>% filter(!is.na(e3_spend_pe_m_concerts) & !is.na(financial_pct_score) & !is.na(psx_group_id) &  !is.na(client_pe_tkt_cnt))


model_concert <- randomForest::randomForest(e3_spend_pe_m_concerts ~ financial_pct_score + personicx_group + client_pe_tkt_cnt, data = data_train_concert, ntree = 1000)

data_train_concert$predicted_dollars_concert <- predict(object = model_concert, data = data_train_concert)

data_train_concert <- data_train_concert%>%mutate(PredictedTotalSpendConcert = predicted_dollars_concert * e3_events_cnt)

ggplot(data_train_concert, aes(x= PredictedTotalSpendConcert, fill = CityName)) + geom_density(alpha= .5) + xlim(0,2000) + labs(fill = "City", x = "Predicted Total Spend on Concerts")

spend_by_city_concert <- data_train_concert %>% 
  group_by(CityName) %>% 
  summarise(City_Spend_concert = mean(predicted_dollars_concert),
            City_Spend_sd_concert = sd(predicted_dollars_concert),
            total_spend_concert = sum(predicted_dollars_concert),
            sample_size_concert = n())

```


### Zip Codes

Hardcoding roughly where we expect the stadiums to be built

```{r Hardcode Zips}
kc_zip <- 64129 #arrowhead
vb_zip <- 23456 #vb sports complex
lville_zip <- 40208 #cardinal stadium 
```

```{r Zip Diagnostics}
ggplot(continuous, aes(x= cust_postal_cd )) + 
  geom_histogram() +
  facet_wrap(~CityName) + 
  labs(x = "Zip Code")
```

# Where are different types of fans


```{r}
population <- data.frame (city  = c("Virginia Beach", "Lousiville", "Kansas City"),
                  population = c(1800000, 1400000, 2200000))

fan_types <-
  continuous %>% 
  select(contains("propn_score_minor_4"), CityName) %>% 
  pivot_longer(values_to = "score", cols = c(contains("propn")), names_to = "Prop") %>%
  left_join(population, by = c("CityName" = "city"))%>%
  left_join(read_csv("prop_join.csv")) %>%
  mutate(prop_number = as.numeric(substring(Prop,nchar(Prop)-3+1), nchar(Prop))) %>%
  filter(between(prop_number, 410, 450)) %>% 
  mutate(super_fan = ifelse(score >= 650, 1, 0),
         regular_fan= ifelse(score >= mean(score, na.rm=T), 1, 0),
         Sport = sub(".*:", "", Sport))

fan_totals <-
  fan_types %>% 
  filter(!str_detect(Sport, "College"))%>% 
  group_by(CityName) %>% 
  summarise(city_total_regular_fans = sum(regular_fan, na.rm= T))

fan_types_by_city <- 
  fan_types %>% 
  filter(!str_detect(Sport, "College")) %>%
  group_by(CityName, Sport) %>%
  summarise(population = mean(population),
            avg_score = mean(score, na.rm=T),
            regular_fans =  sum(regular_fan, na.rm=T), 
            super_fans = sum(super_fan, na.rm=T),
            ct = n(),
            expected_super_fans = super_fans*population/ct,
            expected_regular_fans = regular_fans*population/ct,
            ) %>%
  left_join(fan_totals) %>% 
  rowwise() %>%
  mutate(perc_by_sport = regular_fans/city_total_regular_fans) %>% 
  left_join(spend_by_city) %>%
  mutate(FINAL_SPEND = total_spend * expected_regular_fans/sample_size * perc_by_sport)%>%
  left_join(spend_by_city_concert) %>%
   mutate(FINAL_SPEND_concert = total_spend_concert * expected_regular_fans/sample_size)
```


```{r}
ggData <- fan_types_by_city %>%
  mutate(reg2 = expected_regular_fans-expected_super_fans) %>%select(CityName, Sport, reg2, expected_super_fans) %>% pivot_longer(cols = c("reg2", "expected_super_fans"))%>%
  rename(type = name)
```


```{r}
ggplot(ggData, aes(x= Sport, y = value/1000000, fill = Sport,linetype=  type)) + 
  geom_col(color ="black") +
  facet_wrap(~CityName)+
  labs(x = "Sport", y = "Millions of Fans", title = "Expected Fans")+ 
  ggthemes::theme_economist()+
  theme(axis.text.x = element_text(angle = 90))+ylim(0,1.7) +
  scale_linetype_manual(values=c("dotted", "blank"))+
  guides(linetype =F)
```


```{r}
ggplot(
  fan_types_by_city, aes(x= Sport, y = expected_regular_fans/1000000, fill = Sport)) + 
  geom_col() +
  facet_wrap(~CityName)+
  labs(x = "Sport", y = "Millions of Regular Fans", title = "Expected Regular Fans")+ 
  ggthemes::theme_economist()+
  theme(axis.text.x = element_text(angle = 90))+ylim(0,1.7)

ggplot(fan_types_by_city, aes(x= Sport, y = expected_super_fans/1000000, fill = Sport)) + 
  geom_col() +
  facet_wrap(~CityName)+
  labs(x = "Sport", y = "Millions of Super Fans", title = "Expected Super Fans")+ 
  ggthemes::theme_economist()+
  theme(axis.text.x = element_text(angle = 90)) +ylim(0,1.7)

ggplot(fan_types_by_city, aes(x= Sport, y = FINAL_SPEND/1000000, fill = Sport)) + 
  geom_col() +
  facet_wrap(~CityName) +
  labs(x = "Sport", y = "Million $", title = "Expected Revenue") + 
  ggthemes::theme_economist()+
  theme(axis.text.x = element_text(angle = 90)) + ylim(0,115)
```





